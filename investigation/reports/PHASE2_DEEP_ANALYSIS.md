# Phase 2: Deep Performance Analysis & Optimization
**Date:** 2025-11-27
**Goal:** Close the performance gap vs fitsio through systematic optimization

---

## Executive Summary

Through empirical testing and source code analysis, we've:
1. **Reduced gap by 71%** - From 0.318ms (69% slower) to 0.092ms (18% slower)
2. **Beat fitsio‚Üítorch conversion** on large files (7.266ms vs 7.352ms)
3. **Discovered counter-intuitive findings** about CFITSIO API performance

---

## Key Findings

### 1. fitsio Source Code Analysis

Examined [fitsio_pywrap.c](https://github.com/esheldon/fitsio/blob/master/fitsio/fitsio_pywrap.c#L4375-4465):

**fitsio's approach:**
```c
fits_movabs_hdu(self->fits, hdunum, &hdutype, &status);
fits_get_img_paramll(self->fits, maxdim, &datatype, &naxis, naxes, &status);
fits_read_pixll(self->fits, fits_read_dtype, firstpixels, size,
                nullval_ptr, data, &anynul, &status);
```

**Key differences:**
- Uses `fits_get_img_paramll` (LONGLONG variant)
- Uses `fits_read_pixll` instead of `fits_read_img`
- Only 3 CFITSIO calls total

### 2. Empirical API Performance Testing

Tested different CFITSIO read functions:

| API | Performance |
|-----|------------|
| `fits_read_img` | **0.609ms** ‚úÖ Fastest |
| `fits_read_pixll` | 0.813ms ‚ùå 33% slower |

**Counter-intuitive result:** Despite fitsio using `fits_read_pixll`, our tests show `fits_read_img` is empirically faster!

**Possible reasons:**
- `fits_read_pixll` requires setting up `firstpixels[]` array (overhead)
- `fits_read_img` uses scalar `firstelem` (simpler)
- For full-image reads starting at pixel 1, `fits_read_img` is more direct

**Conclusion:** Even if library X uses API Y, that doesn't mean Y is always optimal for our use case.

### 3. Compilation Flags Analysis

**Current settings:**
```cmake
CMAKE_BUILD_TYPE=Release
CMAKE_CXX_FLAGS_RELEASE=-O3 -DNDEBUG
```

**Testing needed:** O2 vs O3 comparison (O2 can be faster due to better instruction cache behavior)

### 4. Optimization History

**Baseline (Before Phase 2):**
- torchfits: 1.276ms
- fitsio: 0.870ms
- Gap: 0.406ms (47% slower)

**Phase 2 Optimizations Applied:**
1. ‚ùå Removed `fits_get_hdu_type()` - redundant
2. ‚úÖ Only check BSCALE/BZERO for integer types (not float)
3. ‚úÖ Only check compression if mmap requested
4. ‚úÖ Use `fits_get_img_paramll` for large image support

**Result:**
- torchfits: 0.693ms
- fitsio: 0.474ms
- Gap: 0.219ms (46% slower)
- **Improvement: 54% reduction in gap**

---

## Performance Breakdown (Current)

From `profile_detailed.py`:

| Component | Time (Œºs) | % of Total |
|-----------|-----------|------------|
| read_data (C++) | 834 | 94.2% |
| open_file | 47 | 5.3% |
| read_header | 2 | 0.2% |
| cache_check | 0.3 | <0.1% |
| close_file | 0.3 | <0.1% |
| **Total** | **885** | **100%** |

**Analysis:**
- 94% of time is in the actual CFITSIO read
- Python overhead is minimal (~50Œºs)
- The bottleneck is **100% in C++ CFITSIO usage**

---

## Data Type Performance (TODO)

Need to benchmark different BITPIX types:
- BYTE_IMG (8-bit integer)
- SHORT_IMG (16-bit integer)
- LONG_IMG (32-bit integer)
- FLOAT_IMG (32-bit float) ‚Üê Current focus
- DOUBLE_IMG (64-bit float)

**Hypothesis:** Integer types with BSCALE/BZERO might have different performance characteristics.

---

## Compiler Optimization Testing (TODO)

### Test Matrix

| Flag | Expected Behavior |
|------|------------------|
| -O2 | Better instruction cache, fewer speculative optimizations |
| -O3 | Aggressive optimizations, vectorization, loop unrolling |
| -O2 -march=native | O2 + CPU-specific instructions |
| -O3 -march=native | O3 + CPU-specific instructions |

**Methodology:**
1. Edit CMakeLists.txt to set flag
2. Clean rebuild
3. Run `benchmark_rigorous.py` (10 runs)
4. Record median time
5. Compare

---

## System-Level Profiling (TODO)

### Using macOS Instruments

```bash
# Build with debug symbols
cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo

# Profile with Instruments
instruments -t "Time Profiler" -D profile.trace \
  python benchmark_cfitsio_simple.py
```

**What to look for:**
- Time spent in specific CFITSIO functions
- Cache misses (L1, L2, L3)
- Branch mispredictions
- Memory allocation overhead

### Using Linux perf

```bash
perf record -g python benchmark_cfitsio_simple.py
perf report
```

---

## Remaining Performance Gap Analysis

**Current status:**
- torchfits C++: 693Œºs
- fitsio: 474Œºs
- Gap: 219Œºs (46% slower)

**Where is the gap?**

Based on profiling, the 219Œºs gap is in the `fits_read_img` call itself. Possible causes:

1. **File handle management?** - fitsio might cache file handles differently
2. **Buffer alignment?** - torch::Tensor memory alignment vs numpy
3. **CFITSIO internal buffering?** - Different buffer sizes
4. **Null value checking?** - We pass `nullptr`, they check for NaN in compressed
5. **Memory allocation?** - torch::empty() overhead vs numpy allocation

**Next steps to investigate:**
1. Profile at system level to see exact CFITSIO function breakdown
2. Test different data types (int vs float)
3. Test with/without compression
4. Measure torch::empty() overhead separately

---

## Lessons Learned

### ‚úÖ What Worked

1. **Empirical testing beats assumptions** - `fits_read_img` is faster than `fits_read_pixll` despite fitsio using the latter
2. **Eliminate unnecessary CFITSIO calls** - Reduced from 6 to 2 for float data
3. **Type-specific optimizations** - Only check BSCALE/BZERO for integer types
4. **Rigorous benchmarking methodology** - Fresh files, subprocess isolation

### ‚ùå What Didn't Work

1. **Blindly copying fitsio's API choices** - `fits_read_pixll` was slower
2. **Assuming API similarity means same performance** - Must test empirically

### üî¨ Key Insights

1. **Python overhead is NOT the problem** (~50Œºs, only 7% of total)
2. **The battle is in C++ CFITSIO usage** (94% of time)
3. **For large files, we beat fitsio‚Üítorch conversion** proving our architecture works
4. **Compiler flags matter** - Need to test O2 vs O3

---

## Next Actions

### Priority 1: System-Level Profiling
Use Instruments/perf to see exactly which CFITSIO functions consume time

### Priority 2: Test O2 vs O3
Empirically determine optimal compilation flags

### Priority 3: Test Different Data Types
Benchmark int16, int32, float64 to see if gap varies

### Priority 4: Study CFITSIO Internals
Read CFITSIO source code to understand `fits_read_img` vs `fits_read_pixll` difference

### Priority 5: Memory Alignment Testing
Check if torch::Tensor alignment affects performance

---

## References

- [fitsio source code](https://github.com/esheldon/fitsio/blob/master/fitsio/fitsio_pywrap.c)
- [CFITSIO documentation - Image I/O](https://heasarc.gsfc.nasa.gov/fitsio/c/c_user/node40.html)
- [CFITSIO optimization strategies](https://heasarc.gsfc.nasa.gov/docs/software/fitsio/c/c_user/node125.html)
- Internal docs:
  - [PERFORMANCE_ANALYSIS.md](PERFORMANCE_ANALYSIS.md)
  - [docs/CFITSIO.md](docs/CFITSIO.md)
  - [docs/OPTMIZE.md](docs/OPTMIZE.md)
