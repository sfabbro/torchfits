[workspace]
preview = ["pixi-build"]
channels = ["conda-forge"]
platforms = ["osx-arm64"]

[package]
name = "torchfits"
version = "0.1.1"
description = "High-performance FITS I/O for PyTorch"
authors = ["Seb Fabbro <sebfabbro@gmail.com>"]

[package.build]
backend = { name = "pixi-build-cmake", version = "*"}

# Build dependencies - tools needed to build the package
# Note: cmake, ninja, and cxx-compiler are automatically provided by pixi-build-cmake
[package.build-dependencies]
nanobind = ">=2.10.2,<3"
scikit-build-core = ">=0.11.6,<0.12"
cmake = ">=3.21"
ninja = ">=1.10"
python = ">=3.11,<3.14"
pytorch = ">=2.0"
cfitsio = ">=4"
wcslib = ">=7.11"

# Host dependencies - libraries that will be linked into the package
[package.host-dependencies]
python = ">=3.11,<3.14"
pytorch = ">=2.0"
cfitsio = ">=4"
wcslib = ">=7.11"
nanobind = ">=2.10.2,<3"
#dlpack = "*"


# Run dependencies - packages needed at runtime
[package.run-dependencies]
pytorch = ">=2.0"
pytorch-frame = ">=0.2.5"
psutil = ">=5.0"  # For system resource monitoring
cfitsio = ">=4"
wcslib = ">=7.11"

# Workspace dependencies - development environment
[dependencies]
# torchfits = { path = "." }  # Don't add self-dependency - causes circular dependency
pytest = ">=9.0.2,<10"
pytest-cov = ">=7.0.0,<8"
ruff = ">=0.14.14,<0.15"
mypy = ">=1.19.1,<2"
pip = ">=25.3,<26"
astropy = ">=7.2.0,<8"
fitsio = ">=1.3.0,<2"
matplotlib = ">=3.10.8,<4"
seaborn = ">=0.13.2,<0.14"
pandas = ">=2.3.3,<3"
psutil = ">=7.2.1,<8"
scikit-build-core = ">=0.11.6,<0.12"
cmake = ">=4.2.2,<5"
ninja = ">=1.13.2,<2"
nanobind = ">=2.10.2,<3"
python = ">=3.13.11,<3.14"
pytorch = ">=2.10.0,<3"
pytorch-frame = ">=0.2.5,<0.3"
cfitsio = ">=4.6.3,<5"
wcslib = ">=8.2.2,<9"
tabulate = ">=0.9.0,<0.10"

[tasks]
# Development tasks
dev = "pip install -e . --no-build-isolation"
build = "pixi build"
test = "pytest tests/"
lint = "ruff check . && ruff format ."
verify = "python verify_setup.py"

# Core benchmarks (essential)
bench = "python benchmarks/benchmark_all.py --output-dir benchmark_results"
bench-fast = "python benchmarks/benchmark_fast.py --output benchmark_results/fast_results.csv"
bench-fast-stable = "python benchmarks/benchmark_fast.py --output benchmark_results/fast_results.csv --torch-threads 1 --compressed-repeats 3"
bench-basic = "python benchmarks/benchmark_basic.py"
bench-core = "python benchmarks/benchmark_core.py"
bench-ml = "python benchmarks/benchmark_ml.py"
bench-table = "python benchmarks/benchmark_table.py"

# Comprehensive benchmarks (renamed from exhaustive)
bench-all = "python benchmarks/benchmark_all.py"
bench-all-keep = "python benchmarks/benchmark_all.py --no-cleanup"

# Comprehensive benchmark runner
bench-all-auto = "python benchmarks/run_all_benchmarks.py --no-exhaustive"
bench-all-runner = "python benchmarks/run_all_benchmarks.py"
bench-all-force = "python benchmarks/run_all_benchmarks.py --exhaustive"
bench-transforms = "python benchmarks/benchmark_transforms.py"
bench-buffer = "python benchmarks/benchmark_buffer.py"
bench-cache = "python benchmarks/benchmark_cache.py"
bench-focused = "python benchmarks/benchmark_transforms.py && python benchmarks/benchmark_buffer.py && python benchmarks/benchmark_cache.py"

# Pytest-based benchmarking
bench-pytest = "pytest benchmarks/ --benchmark-only"

# Development tools
notebook = "jupyter lab"

# Test phases for development workflow
test-phase1 = "python -c 'import sys; sys.path.insert(0, \"src\"); import torchfits; print(\"Phase 1 COMPLETE: All core features implemented\")'"
test-comprehensive = "python examples/example_comprehensive_ml_pipeline.py"
test-transforms = "python -m pytest tests/test_transforms.py -v"
test-dataloader = "python -m pytest tests/test_dataloader.py -v"
test-buffer = "python -m pytest tests/test_buffer.py -v"

# Test feature with comparison libraries
[feature.test.dependencies]
astropy = ">=7.2.0,<8"
fitsio = ">=1.3.0,<2"

# Benchmark feature with additional dependencies
[feature.bench.dependencies]
astropy = ">=7.2.0,<8"
fitsio = ">=1.3.0,<2"
matplotlib = ">=3.10.8,<4"
seaborn = ">=0.13.2,<0.14"
pandas = ">=2.3.3,<3"
psutil = ">=7.2.1,<8"
pytest-benchmark = ">=5.2.3,<6"

# Environment definitions
[environments]
default = { solve-group = "default" }
test = { features = ["test"], solve-group = "default" }
bench = { features = ["bench"], solve-group = "default" }
